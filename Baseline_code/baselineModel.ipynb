{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baselineModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaG_V9027o0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65a1d30-2c6e-43ea-f306-7c3575416dab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RiKv_r9KsiP",
        "outputId": "128d3273-0b50-4319-e5c3-1b63c4948f35"
      },
      "source": [
        "import csv\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "from nltk import word_tokenize\n",
        "import gensim \n",
        "from gensim.models import Word2Vec \n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download(\"stopwords\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIO6H6lwJn8l"
      },
      "source": [
        "original=[]\n",
        "changed = []\n",
        "with open('/content/drive/MyDrive/IR Project/archive/Questions.csv', encoding=\"latin1\") as csvfile ,open('/content/drive/MyDrive/IR Project/archive/Output.csv' ,'w' ,newline='') as myfile:\n",
        "  readCSV = csv.reader(csvfile, delimiter=',' )\n",
        "  writeCSV = csv.writer(myfile , delimiter = ',')\n",
        "  next(readCSV, None) \n",
        "  for row in readCSV:\n",
        "    doc_id = row[0];\n",
        "    title = row[5];\n",
        "    original.append(title)\n",
        "    data = preprocessing(title)\n",
        "    replace = row[5].replace(title,data)\n",
        "    row[5] = replace\n",
        "    changed.append(row[5])\n",
        "    writeCSV.writerow({row[5]})\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DCuskY_bu-w"
      },
      "source": [
        "for doc in questions:\n",
        "  w =doc.split()\n",
        "  print(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyWYar6TMLyz"
      },
      "source": [
        "stop_words=stopwords.words('english')\n",
        "stemming = PorterStemmer()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk1ZgaePLV-A"
      },
      "source": [
        "def preprocessing(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace(\"?\",\" ?\")\n",
        "  text = text.split()\n",
        "  words = [stemming.stem(w) for w in text if not w in stop_words]\n",
        "  sentence  = ' '.join(words)\n",
        "  return sentence\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLmVcVFhQr25"
      },
      "source": [
        "with open('/content/drive/MyDrive/IR Project/archive/Output.csv' ,'w' ,newline='') as myfile:\n",
        "  writeCSV = csv.writer(myfile , delimiter = ',')\n",
        "  for w in changed:\n",
        "    writeCSV.writerow({ w })\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPSmesMRqVZW"
      },
      "source": [
        "changed = np.array(changed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-4ViU2apOz2"
      },
      "source": [
        "np.savetxt(\"Output.csv\",  \n",
        "           changed, \n",
        "           delimiter =\", \",  \n",
        "           fmt ='% s') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnW9q7bWq2sV"
      },
      "source": [
        "changed = list(changed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKQ4UhXi72ZX"
      },
      "source": [
        "changed = []\n",
        "with open('/content/drive/MyDrive/IR project/Output.csv', encoding=\"latin1\") as csvfile:\n",
        "  readCSV = csv.reader(csvfile, delimiter=',' )\n",
        "  for row in readCSV:\n",
        "    title = row[0];\n",
        "    changed.append(title)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzil9YbBaPEx",
        "outputId": "118831fb-be8b-4a10-94bf-3491da667087"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2cioNbQ6kT9"
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkaPsAue7YLK"
      },
      "source": [
        "model_w2v = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/IR Project/Pre-Trained model/SO_vectors_200.bin\", binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBdmBlo38sKL"
      },
      "source": [
        "filename = \"/content/drive/MyDrive/IR Project/W2V_model.sav\"\n",
        "pickle.dump(model_w2v, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uFd0kDHjY_M"
      },
      "source": [
        "model_w2v = pickle.load(open(\"/content/drive/MyDrive/IR project/W2V_model.sav\", 'rb'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIfIaPdMadZq"
      },
      "source": [
        "#model_w2v = gensim.models.Word2Vec(words , size=300, window=10 , negative=25)\n",
        "#model_w2v.train(words, total_examples=len(words), epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSrRkhlek9RQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "def tfidfModel(sentences):\n",
        "  tfidf_model = TfidfVectorizer()\n",
        "  tfidf_model.fit(sentences)\n",
        "  word_Tfidf_Dict = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\n",
        "  tfidf_features = tfidf_model.get_feature_names()\n",
        "  return word_Tfidf_Dict, tfidf_features"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me_K9aNcmhKa"
      },
      "source": [
        "dictionary, features = tfidfModel(changed)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msd9hattk9bk"
      },
      "source": [
        "def tfidfWeightedWord2vec(sentences, dictionary, features):\n",
        "  x_train = []\n",
        "  w2v_vocab = list(model_w2v.wv.vocab)\n",
        "  for sent in sentences:\n",
        "    #print(sent)\n",
        "    sent_vec = np.zeros(200)\n",
        "    ti_idf_score_sum = 0 \n",
        "    wordlist = sent.split(\" \")\n",
        "    #print(wordlist)\n",
        "    for word in wordlist:\n",
        "      if word in w2v_vocab and word in features:\n",
        "        word_vec = model_w2v.wv[word]\n",
        "        tf_idf_score = dictionary[word]*(wordlist.count(word)/len(wordlist))\n",
        "        sent_vec += (word_vec * tf_idf_score)\n",
        "        ti_idf_score_sum += tf_idf_score \n",
        "    if (ti_idf_score_sum !=0):\n",
        "      sent_vec = sent_vec/ti_idf_score_sum\n",
        "    x_train.append(sent_vec) \n",
        "  return x_train  "
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-wiHfCeqmS8"
      },
      "source": [
        "sliced_data = changed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nwt-CrbQ5pF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6250e6cb-26e7-4a55-c35a-ad5d90b59d27"
      },
      "source": [
        "x_train = tfidfWeightedWord2vec(sliced_data, dictionary, features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4hT_AAer4K0"
      },
      "source": [
        "df = pd.DataFrame(x_train)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djr9C2DWr4Nu"
      },
      "source": [
        "df.to_csv(\"/content/drive/MyDrive/IR project/combined/w2vembeddings_full_combined.csv\" ,header=None, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU8uDYKkZoC-"
      },
      "source": [
        "def readCsv(path):\n",
        "  with open(path, encoding=\"latin1\") as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',' )\n",
        "    test_data_embeddings = []\n",
        "    for row in readCSV:\n",
        "      embedd = []\n",
        "      for i in range(0,len(row)):\n",
        "        embedd.append(row[i])\n",
        "      embedd = [(float)(word_embedding) for word_embedding in embedd]\n",
        "      test_data_embeddings.append(embedd)   \n",
        "  return test_data_embeddings"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bxjLlRrkDcl"
      },
      "source": [
        "def getTitleList():\n",
        "  titleList = []\n",
        "  with open('/content/drive/MyDrive/IR project/Questions.csv', encoding=\"latin1\") as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',' )\n",
        "    next(readCSV, None) \n",
        "    for row in readCSV:\n",
        "      title = row[5];\n",
        "      titleList.append(title)\n",
        "  return titleList    \n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDZZ1vOBma6y"
      },
      "source": [
        "titlelist = getTitleList()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7QRozDEhgZI"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "def calCosSim(test_query_embedding, embeddings, titlelist):\n",
        "  test_query_embeddingArr = np.array(test_query_embedding)\n",
        "  embeddingsArr = np.array(embeddings)\n",
        "  result = distance.cdist(test_query_embeddingArr, embeddingsArr, \"cosine\")\n",
        "  final_res = 1-result[0]\n",
        "  final_list = list(zip(final_res, titlelist))\n",
        "  final_list.sort(reverse=True)\n",
        "  return final_list\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kDbObmOqIx_"
      },
      "source": [
        "train_embeddings = readCsv(\"/content/drive/MyDrive/IR project/combined/w2vembeddings_full_combined.csv\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BnaRx_ptYeI",
        "outputId": "5c0e5bf5-048d-4c06-a8bc-eecb6559131c"
      },
      "source": [
        "print(train_embeddings[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20052852835320084, 0.7336173834239724, -1.0453705266423161, 2.3215986288581436, -0.31390727770310894, 0.7074048479329957, 0.7012878087270558, -0.5686441048762712, -0.5200858870098016, 0.12886488413520406, -0.19329062646556783, -1.1943364387535003, 0.79344214032542, -0.45816649287241296, 0.16804326207553733, 0.6293142736762547, -0.03141296339781829, -0.6453076616875263, -0.5186502010446434, 0.06723510531003012, -1.1899817382821094, -3.142119780586133, 1.1117615923945154, 1.6613509834069562, -0.6035607034189209, 0.6522275947174854, 0.00023530728134137828, -0.15453850531424962, -1.1309983819024794, 0.3981271726181166, 1.174100076924874, 0.24799571052188926, -1.0760593482131156, -1.4377396165277019, -1.635493265678283, 0.3745747025213205, -0.1949189382719861, 0.8625509849925447, -0.5867752981620665, -0.22973177939169967, -0.7011575500513022, 1.6495715111317202, -1.439697854011907, 0.994622263601535, 1.1674021713399447, -1.48184971820473, -1.962956409601736, 1.8973748127002508, -0.3904826017175189, -1.5965826372515108, 3.8710218030962027, -1.9518304448858672, -2.008727372187167, 1.353438089904074, -0.48606108918960644, 0.6376777608047243, -0.7553083917679895, -0.33598775200149805, -0.6841677335444808, 0.3115560855176918, -0.4250548817525714, -1.0786347640084737, -0.2838452544713476, -1.3872092551643551, 0.7037144457187957, -0.3753092346780935, 1.9293986247806931, -2.135025113051355, 0.23223364465168037, -0.7639242118780607, -0.8663012797512601, -0.7951218097876143, -0.25735435490295105, 0.2808556103325675, -0.9146931061172404, -0.2187943516554206, 1.1571691902601409, 0.10484847262670455, 1.3849336840941358, -1.639203455065475, 0.041110175390080377, 0.3528593359168797, 1.5646638653809957, 0.9354635313150098, 0.2909299859251781, -0.04610661287944744, -0.47848365873744225, -0.26324754288148383, -1.0524206343914217, 0.42017908627808265, 0.49976567981668396, -1.8982353525299098, -1.1162766618791204, 0.9107162663484004, 0.07294481364508698, 1.2671082780004714, -0.5612600177445376, -1.759455333036219, 0.08385634811431106, -0.6454595559809024, 0.5779999073261862, 1.700057893225769, 1.405817327574992, 0.2570893500708002, -1.31347967812453, 0.6932696141340068, -0.790021900677594, -0.4462282859392457, -0.38730894262443855, -1.1799210277641996, 0.43261400288666363, 0.9138160450266016, -1.1128465188498609, 0.9641038031045494, -1.2567121074901875, 0.466780338602943, -1.4365000468997395, -0.5819193067830735, 1.5166212649174737, 0.41437217158416967, 1.594989825097084, -1.1239067131841767, -0.7480641441601444, 0.5170138070155251, -0.1712497433044842, 1.5725984776735886, 0.8538704231442658, 0.4430734653094983, -1.0747329870433948, -0.6685686729249456, 1.0044438671019984, 0.7410918487936791, 1.4783155928187914, 0.21236123174091606, -2.2916137659460416, -0.5819556935765453, -0.3218034609577649, -0.3241626052331412, -0.96320665836915, -0.6299576870278172, -0.11770999934168842, -0.733006935983966, -0.14688458024835588, 0.1049303750953822, -0.6683234559654252, 0.7654331538308337, 1.8186877992399035, 0.00471274461613741, -0.7908458858005671, -0.8446513314353518, -1.5444591992704253, 1.5758529785835451, 1.1549761107541248, -0.7725407330258003, 0.1533049154956206, 2.273122671675208, 0.7833845510692851, -0.41291454495904995, -1.1508199610117134, -0.8744482616805249, -1.5006130956459023, -1.036188826582514, 0.144631507012622, -0.9391614700339644, 0.14387492339065724, 1.2839722792349646, -0.5086386013730709, 0.9718539233769138, 0.12631924984726223, -2.3931385112424914, -1.6729651041941724, 0.2120862835604886, -0.6999353993203763, 0.9253391991799573, 1.7092749916649053, -0.5553433997508173, -0.7202732297049408, 0.24008844167182752, 0.4567911108391444, -0.6336990785381799, -1.2031544571573058, 0.013115191808083198, -1.2841948228382178, -0.04006620996401129, 1.567367018355344, -0.925608298295976, 0.9426771291641944, -0.6147063781726492, -0.7628362993660599, 1.8493391099716319, -0.46178335749454563, -1.5617310603024257, -0.7010115341196925, -0.28170345706016114, 2.0248711789544465, -1.3520869503410755, -0.411219760509043, 1.2128398242715976, 1.9717851602835597, -0.10956782838836886]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUkXwi6QbgEW",
        "outputId": "4cbf1158-42df-481d-f97e-9d2bd9933747"
      },
      "source": [
        "queries = ['insert query in sql table', 'tags in html and css', 'concatenate a string in C#' ]\n",
        "for query in queries:\n",
        "  processed_test_query = preprocessing(query)\n",
        "  print(\"query: \", query)\n",
        "  test_query_embeddings = tfidfWeightedWord2vec([processed_test_query], dictionary, features)\n",
        "  final_list = calCosSim(test_query_embeddings, train_embeddings, titlelist)\n",
        "  print(\"relevant result with score:\")\n",
        "  for f in final_list[:10]:\n",
        "    print(f[0],\" : \", f[1])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "query:  insert query in sql table\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "relevant result with score:\n",
            "0.9324066561222449  :  sql - insert into multiple tables in one query\n",
            "0.8910677098747644  :  Is it possible in boost::ireplace to treat special characters like basic characters? (eg. 'รยบ' as 'z')\n",
            "0.8905303864712878  :  MySQL INSERT ...SELECT with SUBQUERY\n",
            "0.8767070552551252  :  Error in downloading.... The archived file is corrupted or damaged\n",
            "0.8707882927629336  :  Rails 3 CSV imports to raise errors in resulting view\n",
            "0.8631997106588076  :  How to display page loading GIF on page with <frameset>?\n",
            "0.8629816151076443  :  SQL Delete (Suspended in activity monitor)\n",
            "0.8625800477254546  :  iOS (Xcode 6.2) Paypal (2.11.0) integration - 64 duplicate symbols for architecture arm64\n",
            "0.8625800477254545  :  How to update an SQL table with F#\n",
            "0.8567235539070933  :  has_many relation works on localhost but not server (Heroku)\n",
            "\n",
            "\n",
            "query:  tags in html and css\n",
            "relevant result with score:\n",
            "0.9293471065464471  :  Empty HTML tags\n",
            "0.9039089091488283  :  Importing text data with variable size separators in kdb\n",
            "0.867973562648991  :  <br /> HTML tag not cross-browser compatible\n",
            "0.8466020822595567  :  HTML colspan in CSS\n",
            "0.8437874303235314  :  referencing CSS\n",
            "0.8391164596125376  :  Managing CSS Explosion\n",
            "0.8384570824379651  :  Ignore whitespace in HTML\n",
            "0.8380896753165786  :  How do I get the default mail client using Powershell?\n",
            "0.8377738680374183  :  CSS div#id what for?\n",
            "0.8377738656038899  :  CSS first-child\n",
            "\n",
            "\n",
            "query:  concatenate a string in C#\n",
            "relevant result with score:\n",
            "0.9999999999999999  :  C# string won't concatenate\n",
            "0.9993876714343742  :  String as a parameter\n",
            "0.99825010229404  :  ruby string encoding\n",
            "0.9928204127897318  :  How to release the unused capacity of a string\n",
            "0.9904800793068651  :  Comparing a possibly empty string in C#\n",
            "0.9776050702626582  :  Checking for string contents? string Length Vs Empty String\n",
            "0.9770865073100988  :  C# string concatenation and string interning\n",
            "0.9756627549928963  :  String parsing in C\n",
            "0.9712454821598383  :  Changing a string\n",
            "0.9670564701713784  :  strpos and string in string searches\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}